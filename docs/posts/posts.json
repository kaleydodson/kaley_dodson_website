[
  {
    "path": "posts/2021-02-24-chloropleth/",
    "title": "Chloropleth Map",
    "description": "Spatial data visualization using ggplot.",
    "author": [],
    "date": "2021-02-28",
    "categories": [],
    "contents": "\nHere I created a static map in ggplot illustrating inland oil spill events by county. After joining spatial data for CA counties with a dataset for oil spills in the state, I used geom_sf() to create a chloropleth map in which the fill color depended on the count of inland oil spill events by county.\n\nShow code\n# read in data\nca_counties <- read_sf(here(\"data\", \"ca_counties\"), layer = \"CA_Counties_TIGER2016\") %>% \n  clean_names() %>% \n  select(name)\n\noil_spills <- read_sf(here(\"data\", \"ds394\"), layer = \"ds394\") %>% \n  clean_names() \n\n# check projection\nst_crs(ca_counties)\nst_crs(oil_spills)\n\nca_counties <- st_transform(ca_counties, st_crs(oil_spills)) # transforms to same crs as oil spill dataset\n\n# combine data sets to bid spill counts to counties\ncounty_spills <- ca_counties %>% \n  st_join(oil_spills)\n\nspills_count <- county_spills %>% \n  filter(inlandmari == \"Inland\") %>% \n  count(name)\n\nggplot(data = spills_count) +\n  geom_sf(aes(fill = n), color = \"lightgray\", size = 0.2) +\n  scale_fill_gradientn(colors = c(\"white\",\"orange\",\"red\")) +\n  theme_minimal() +\n  labs(fill = \"Number of inland oil spills\")\n\n\n\n\nFigure 1: Total inland oil spills by county in 2008\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-24-chloropleth/chloropleth_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-02-28T09:31:39-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-28-stats/",
    "title": "Statistical Analysis",
    "description": "A sample report using PCA.",
    "author": [],
    "date": "2021-02-28",
    "categories": [],
    "contents": "\n1. Introduction\nThis mini-report uses data compiled by Zander Venter using Google Earth Engine to summarize environmental and climatic variables for countries across the globe. The report explores the relationships among a subset of those variables, including country elevation, cropland cover, tree canopy cover, average annual rainfall and temperature, wind and cloudiness, using principal components analysis. The results are visualized in a biplot and interpreted in a brief summary.\n2. Exploratory Findings & Summary\n\nShow code\n# read in data\nworld_env_vars <- read.csv(here(\"data\", \"world_env_vars.csv\"))\n\n# wrangling + pca \nworld_env_vars_pca <- world_env_vars %>% \n  select(elevation, cropland_cover, tree_canopy_cover, rain_mean_annual, temp_mean_annual, wind, cloudiness) %>% # retains only the variables elevation, cropland and tree canopy cover, average annual rain and temperature, wind, & cloudiness\n  drop_na() %>% # removes na values for the above variables\n  scale() %>% # scales data to create equal units of measurement\n  prcomp() # principal components analysis\n\n# to see loadings\nworld_env_vars_pca$rotation\n\n# biplot\nworld_env_vars_complete <- world_env_vars %>% \n  drop_na(elevation, cropland_cover, tree_canopy_cover, rain_mean_annual, temp_mean_annual, wind, cloudiness) # creates data subset to match that used for pca\n\nautoplot(world_env_vars_pca,\n         data = world_env_vars_complete,\n         colour = 'seagreen2',\n         loadings = TRUE,\n         loadings.label = TRUE,\n         loadings.colour = \"black\",\n         loadings.label.colour = \"black\",\n         loadings.label.vjust = -.5,\n         loadings.label.hjust = 1,\n         loadings.label.size = 3.25) +\n  theme_minimal() +\n  labs(x = \"Component 1 (40.33%)\", y = \"Component 2 (20.95%)\")\n\n\n\n\nFigure 1: Relationships among select environmental and climatic variables for countries across the globe. Vectors indicate loadings of variables along each principal component. Data: Venter, 2018\n\n\n\nSummary\nMajor takeaways from the PCA include:\nTree canopy cover and average annual rainfall are positively correlated.\nCropland cover and elevation are positively correlated.\nCropland cover and average annual temperature are negatively correlated.\nWind and tree canopy cover are negatively correlated.\nCloudiness and cropland cover are minimally correlated.\nThere are no observable clusters of observations and only a couple of outliers.\nCloudiness, tree canopy cover, and average annual rainfall are heavily loaded in the direction of the first principal component.\nAverage annual temperature and cropland cover are heavily loaded in the direction of the second principal component.\nOver 60% of total variance is represented.\n\n\n\n",
    "preview": "posts/2021-02-28-stats/stats_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-02-28T09:46:27-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-27-raster/",
    "title": "Working With Rasters",
    "description": "Visualizing raster data in R.",
    "author": [],
    "date": "2021-02-27",
    "categories": [],
    "contents": "\nHere I read in a raster stack and wrote a function to determine the presence of cetacean speices. After applying the function, I calculated overall cetacean species richness and then converted the raster to a dataframe. Finally, I visualized the result by layering raster data with spatial data from the rnaturalearthdata package.\n\nShow code\n# read in data\ncetacean_richness <- here(\"data\", \"ca_cetaceans\")\n\ncetaceans <- dir(cetacean_richness, full.names = TRUE, pattern = \"*.tif\")\n\ncetaceans_stack <- stack(cetaceans)\n\n# threshold function\nis_present <- function(x, thresh = .75) {\n  y <- ifelse(x >= thresh, 1, NA)\n  return(y)\n}\n\n# calculating species richness \ncetaceans_richness <- calc(cetaceans_stack, fun = is_present)\n\nspecies_richness <- calc(cetaceans_richness, fun = sum, na.rm = TRUE)\n\n# download ca coastline layer from rnaturalearth\ncoastline <- ne_download(scale = \"medium\", type = 'land', category = 'physical', returnclass = \"sf\")\n\n# convert raster to data frame\nspecies_richness_df <- raster::rasterToPoints(species_richness) %>% \n  as.data.frame()\n\n# visualization\nggplot() +\n  geom_raster(data = species_richness_df, aes(x = x, y = y, fill = layer)) +\n  geom_sf(data = coastline, fill = \"lavender\") +\n  coord_sf(xlim = c(-125,-115), ylim = c(33,37)) +\n  scale_fill_gradient(low = \"skyblue4\", high = \"seagreen3\") +\n  theme_void() \n\n\n\n\nFigure 1: Map of cetacean species richness in the California Bight, using a threshold of 75% probability of occurence to determine presence for each species.\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-27-raster/raster_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-02-28T09:36:33-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-27-timeseries/",
    "title": "Timeseries Plot",
    "description": "Wrangling and visualizing time series data.",
    "author": [],
    "date": "2021-02-27",
    "categories": [],
    "contents": "\nAs part of a report exploring data for adult fish passage recorded from 2001-01-01 to 2010-12-31 on the Willamette River in Oregon, I worked with time series data. After tidying the data using the pivot_longer() function and converting to a tsibble, I wrangled to aggregate counts by year and produced the following summary plot.\n\nShow code\n# read in data \nwillamette_fish <- read.csv(here(\"data\", \"willamette_fish_passage.csv\")) %>% \n  clean_names() \n\n# data wrangling, turn dataset into a tsibble\nfish_ts <- willamette_fish %>% \n   pivot_longer( # tidy's data by consolidating steelhead, coho, and jack_coho columns called species into one and their respective observations into a second colunm called fish_count\n    cols = c(steelhead, coho, jack_coho),\n    names_to = \"species\",\n    values_to = \"fish_count\"\n  ) %>% \n  mutate(date = mdy(date)) %>% # converts date to y-m-d format\n  as_tsibble(key = species, index = date) %>% # converts data to tsibble\n  select(date, species, fish_count) %>% # retains only date, species, and fish_count variables\n  mutate(species_name = case_when( # creates new column with species' full names\n    species == \"coho\" ~ \"Coho\",\n    species == \"jack_coho\" ~ \"Jack Coho\",\n    species == \"steelhead\" ~ \"Steelhead\"\n  ))\n\n# wrangling to aggregate fish counts by year\nfish_annual <- fish_ts %>% \n  index_by(year = ~year(.)) %>% # groups observations by year\n  group_by(species_name) %>% # groups observations by species\n  summarize(total_count = sum(fish_count, na.rm = TRUE)) # counts observations per year by species\n\n#vizualization of annual counts\nggplot(data = fish_annual, aes(x = year, y = total_count, fill = species_name)) +\n  geom_col(show.legend = FALSE, color = \"#317eb1\") +\n  facet_wrap(~species_name, scales = \"free\") +\n  theme_bw() +\n  labs(x = \"Year\", y = \"Individuals Observed\") +\n  scale_x_continuous(breaks = c(2002, 2004, 2006, 2008, 2010)) +\n  theme(axis.text.x = element_text(angle = 30)) +\n  scale_y_continuous(labels = scales::comma) +\n  scale_fill_brewer(palette = \"Blues\")\n\n\n\n\nFigure 1: Annual salmon counts at the Willamette Falls fish ladder for steelhead and coho species. (Data: Columbia River DART)\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-27-timeseries/timeseries_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-02-28T09:29:11-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-27-txtanalysis/",
    "title": "Text Analysis",
    "description": "Sentiment analysis using the NRC lexicon.",
    "author": [],
    "date": "2021-02-27",
    "categories": [],
    "contents": "\nI wrangled and visualized the top 100 words that appear in the novel Fear and Loathing in Las Vegas, then joined the data frame with the nrc lexicon before counting words associated with its sentiment bins and visualizing the result.\n\nShow code\n# load text data\nfl_text <- readtext(here(\"data\", \"fear_and_loathing.txt\"))\n\n# wrangling\nfl_tidy <- fl_text %>% \n  mutate(text = str_split(fl_text, pattern = \"\\\\n\")) %>% # splits full text up by line breaks\n  unnest(text) %>% # moves each line of text out to its own row\n  slice(-(1:17)) %>% # removes title pages\n  mutate(text = str_to_lower(text)) %>% # converts all text to lowercase\n  unnest_tokens(word, text) # moves each word out into its own row\n  \nfl_nonstop_words <- fl_tidy %>% \n  anti_join(stop_words) # removes stop words\n\nnonstop_counts <- fl_nonstop_words %>% \n  count(word) # counts total use of each word\n\nfl_nrc <- fl_nonstop_words %>% \n  inner_join(get_sentiments(\"nrc\")) # joins text and nrc dataframes\n\nfl_nrc_counts <- fl_nrc %>% \n  count(sentiment) # counts words that fall into each sentiment category\n\n# visualization\nggplot(data = fl_nrc_counts, aes(x = sentiment, y = n)) +\n  geom_col(fill = rainbow(10)) +\n  coord_flip() +\n  theme_classic() +\n  labs(y = \" \", x = \"nrc sentiment\")\n\n\n\n\nCitation: Thompson, Hunter S, and Ralph Steadman. Fear and Loathing in Las Vegas: A Savage Journey to the Heart of the American Dream. , 1998.\n\n\n\n",
    "preview": "posts/2021-02-27-txtanalysis/txtanalysis_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-02-28T09:33:35-08:00",
    "input_file": {}
  },
  {
    "path": "posts/2021-02-24-tidytues/",
    "title": "Tidy Tuesday",
    "description": "Mapping spatial data with tmap.",
    "author": [],
    "date": "2021-02-11",
    "categories": [],
    "contents": "\nFor my first time participating in TidyTuesday, I made a basic map of total plastic pollution by country using the: 1) dplyr join function to merge lat/long coords from downloaded data; and 2) tmap package to map countriesâ€™ plastic data onto a world map.\n\nShow code\ntuesdata <- tidytuesdayR::tt_load(2021, week = 5)\n\nplastics <- tuesdata$plastics\n\ndata(World)\n\nworld_lat_long <- read.csv(here(\"data\", \"world_country_and_usa_states_latitude_and_longitude_values.csv\")) %>% \n  select(country, latitude, longitude) \n\n# wrangling for total plastic per country\nplastics_subset <- plastics %>% \n  filter(parent_company == \"Grand Total\")\n\n# renames countries in the plastics data so they match countries dataset\nplastics_subset[51, 1] = \"United States\"\nplastics_subset[33, 1] = \"Nigeria\"\nplastics_subset[15, 1] = \"Ecuador\"\nplastics_subset[43, 1] = \"Taiwan\"\n\n# joining with lat & long coordinates\nmerged_data <- left_join(plastics_subset, world_lat_long, by = \"country\") \n\n# convert to lat and long to spatial coordinates\nplastics_sp <- merged_data %>% \n  drop_na(longitude, latitude) %>% \n  st_as_sf(coords = c(\"longitude\", \"latitude\"))\n\nst_crs(plastics_sp) = 4326\n\n# map\ntm_shape(World) +\n  tm_borders(\"thistle\", lwd = .5) +\ntm_shape(plastics_sp) +\n  tm_bubbles(size = \"grand_total\") \n\n\n\n\n\n\n\n",
    "preview": "posts/2021-02-24-tidytues/tidytues_files/figure-html5/unnamed-chunk-1-1.png",
    "last_modified": "2021-02-28T09:40:03-08:00",
    "input_file": {}
  }
]
